{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding:utf-8\n",
    "import random\n",
    "from time import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "from math import sqrt\n",
    "#import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "#%matplotlib inline\n",
    "\n",
    "# ロードは最初しないのでFalse\n",
    "LOAD_MODEL = False\n",
    "\n",
    "# 不正解のデータが入ったcsvを読み込む\n",
    "negative_dataset = np.genfromtxt(\"./negative_calibration.csv\", delimiter=',', dtype=[\"S32\", int, \"S32\",float, float, float, float, float, float, float, float, float, int])\n",
    "# 正解のデータが入ったcsvを読み込む\n",
    "positive_dataset = np.genfromtxt(\"./positive_calibration.csv\", delimiter=',', dtype=[\"S32\", int, \"S32\",float, float, float, float, float, float, float, float, float, int])\n",
    "\n",
    "NUM_CLASSES = 2 #  2クラス分類\n",
    "NUM_STEPS = 2000 #  学習回数\n",
    "LEN_SEQ = 10 # 系列長\n",
    "SIZE_INPUT = 1 # 入力データ数\n",
    "NUM_DATA = 2000  # データ数\n",
    "NUM_TEST = 200 # テスト用のデータ数\n",
    "SIZE_BATCH = 100 # バッチサイズ\n",
    "NUM_NODE = 1024  # ノード数\n",
    "LEARNING_RATE = 0.01  # 学習率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 再実行時にグラフをクリア\n",
    "tf.reset_default_graph()\n",
    "# チェックポイントを作成するディレクトリの指定\n",
    "CKPTDIR = \"./ckptdir-sqrt-test\"\n",
    "if not (os.path.exists(CKPTDIR)):\n",
    "    print\"Please make directory \"+CKPTDIR\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(dataset):\n",
    "    #データセットをnparrayに変換する\n",
    "    #csvに入っている3~6番目の値だけ取得する\n",
    "    raw_data = [list(item)[3:6] for item in dataset]\n",
    "    raw_data = np.array(raw_data)\n",
    "    return raw_data\n",
    "\n",
    "def set_matrix(dataset,length):\n",
    "  tmp = []\n",
    "  ret = []\n",
    "  #(length,10,3)の配列に整形する\n",
    "  for i in range(0,length):\n",
    "    tmp = []\n",
    "    for j in range(0,10):\n",
    "      tmp.append(dataset[i*10+j])\n",
    "    ret.append(np.array(tmp))\n",
    "  return np.array(ret)\n",
    "\n",
    "def create_label(num,length):\n",
    "  #(length,)でnumの値が入った配列を作成する\n",
    "  label = []\n",
    "  for i in range(0,length):\n",
    "    label.append(num)\n",
    "\n",
    "  return np.array(label)\n",
    "\n",
    "def create_sqrt_data(dataset):\n",
    "  tmp = []\n",
    "  sqrt_data = []\n",
    "  for i in dataset:\n",
    "      tmp.append(([sqrt(i[0]*i[0]+i[1]*i[1]+i[2]*i[2])]))  \n",
    "  sqrt_data = np.array(tmp)\n",
    "  return sqrt_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03845439]\n",
      " [ 0.41046332]\n",
      " [ 0.17503982]\n",
      " ..., \n",
      " [ 0.13644959]\n",
      " [ 0.09364342]\n",
      " [ 0.16246258]]\n"
     ]
    }
   ],
   "source": [
    "positive_data = get_data(positive_dataset)\n",
    "positive_sqrt_data = create_sqrt_data(positive_data)\n",
    "print (positive_sqrt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.03845439]\n",
      "  [ 0.41046332]\n",
      "  [ 0.17503982]\n",
      "  [ 0.04931876]\n",
      "  [ 0.14415041]\n",
      "  [ 0.1453848 ]\n",
      "  [ 0.20813779]\n",
      "  [ 0.23448484]\n",
      "  [ 0.17345299]\n",
      "  [ 0.2572931 ]]\n",
      "\n",
      " [[ 0.0879576 ]\n",
      "  [ 0.12526428]\n",
      "  [ 0.07581121]\n",
      "  [ 0.09275527]\n",
      "  [ 0.04842458]\n",
      "  [ 0.1375316 ]\n",
      "  [ 0.12147238]\n",
      "  [ 0.16708184]\n",
      "  [ 0.17770408]\n",
      "  [ 0.32292343]]\n",
      "\n",
      " [[ 0.0298218 ]\n",
      "  [ 0.16319173]\n",
      "  [ 0.17730635]\n",
      "  [ 0.11833402]\n",
      "  [ 0.14913933]\n",
      "  [ 0.28219734]\n",
      "  [ 0.12608703]\n",
      "  [ 0.1685329 ]\n",
      "  [ 0.31950014]\n",
      "  [ 0.05928862]]]\n",
      "[1 1 1]\n"
     ]
    }
   ],
   "source": [
    "positive_main_data = set_matrix(positive_sqrt_data,1000)\n",
    "print positive_main_data[:3]\n",
    "positive_label = create_label(1,1000)\n",
    "print positive_label[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.12478197]\n",
      "  [ 0.11738032]\n",
      "  [ 0.12955902]\n",
      "  [ 0.11811325]\n",
      "  [ 0.11718336]\n",
      "  [ 0.12642523]\n",
      "  [ 0.12278331]\n",
      "  [ 0.12492934]\n",
      "  [ 0.1278747 ]\n",
      "  [ 0.12533371]]\n",
      "\n",
      " [[ 0.12012385]\n",
      "  [ 0.11667879]\n",
      "  [ 0.11382065]\n",
      "  [ 0.12431549]\n",
      "  [ 0.12091956]\n",
      "  [ 0.13090126]\n",
      "  [ 0.11338316]\n",
      "  [ 0.12320041]\n",
      "  [ 0.12898969]\n",
      "  [ 0.10565008]]]\n",
      "[0 0 0]\n"
     ]
    }
   ],
   "source": [
    "negative_data = get_data(negative_dataset)\n",
    "negative_sqrt_data = create_sqrt_data(negative_data)\n",
    "negative_main_data = set_matrix(negative_sqrt_data,1000)\n",
    "print negative_main_data[:2]\n",
    "negative_label = create_label(0,1000)\n",
    "print negative_label[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 10, 1)\n",
      "(2000,)\n",
      "(1800, 10, 1)\n",
      "(1800,)\n",
      "(200, 10, 1)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "#正解と不正解の配列を合わせる\n",
    "x_data = np.r_[positive_main_data, negative_main_data]\n",
    "y_data = np.r_[positive_label, negative_label]\n",
    "print x_data.shape\n",
    "print y_data.shape\n",
    "\n",
    "#配列をシャッフルする\n",
    "index_list = np.arange(0, 2000)\n",
    "np.random.shuffle(index_list)\n",
    "x_shuffle_data = x_data[index_list]\n",
    "y_shuffle_data = y_data[index_list]\n",
    "\n",
    "#学習とテストで分ける\n",
    "x_train_data = x_shuffle_data[NUM_TEST:]\n",
    "y_train_label = y_shuffle_data[NUM_TEST:]\n",
    "x_test_data = x_shuffle_data[:NUM_TEST]\n",
    "y_test_label = y_shuffle_data[:NUM_TEST]\n",
    "print x_train_data.shape\n",
    "print y_train_label.shape\n",
    "print x_test_data.shape\n",
    "print y_test_label.shape\n",
    "\n",
    "#入力データの代入先\n",
    "x = tf.placeholder(tf.float32, [None, LEN_SEQ, SIZE_INPUT])\n",
    "#ラベルの代入先\n",
    "t = tf.placeholder(tf.int32, [None])\n",
    "#出力層での値が、分類したいクラスの数と同じ次元のベクトルとなる配列を返す\n",
    "t_on_hot = tf.one_hot(t, depth=NUM_CLASSES, dtype=tf.float32)\n",
    "\n",
    "# NUM_STEPSとSIZE_BATCHを転置する\n",
    "x_transpose = tf.transpose(x, [1, 0, 2])\n",
    "#(NUM_STEPS*SIZE_BATCH,SIZE_INPUT)にreshapeする\n",
    "x_reshape = tf.reshape(x_transpose, [-1, SIZE_INPUT])\n",
    "x_split = tf.split(x_reshape, LEN_SEQ, 0)\n",
    "lstm_cell = rnn.BasicLSTMCell(NUM_NODE, forget_bias=1.0)\n",
    "outputs, states = rnn.static_rnn(lstm_cell, x_split, dtype=tf.float32)\n",
    "#重み\n",
    "w = tf.Variable(tf.random_normal([NUM_NODE, NUM_CLASSES]))\n",
    "#バイアス\n",
    "b = tf.Variable(tf.random_normal([NUM_CLASSES]))\n",
    "logits = tf.matmul(outputs[-1], w) + b\n",
    "#どのクラス(正解か不正解)に分類されるのが尤もらしいかを表す\n",
    "pred = tf.nn.softmax(logits)\n",
    "\n",
    "#誤差関数\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=t_on_hot, logits=logits)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "#使用するトレーニングアルゴリズムと最小化\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE)\n",
    "train_step = optimizer.minimize(loss)\n",
    "\n",
    "#予想したラベルが教師のラベルと一致しているかを表す\n",
    "correct_prediction = tf.equal(tf.argmax(pred,1), tf.argmax(t_on_hot,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "loss_train = []\n",
    "acc_train = []\n",
    "loss_test = []\n",
    "acc_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialization\n",
      "[10 STEPS] 55.074563 sec\n",
      "[TRAIN] loss : 12.255596, accuracy : 0.510000\n",
      "[TEST loss : 12.170588, accuracy : 0.515000\n",
      "[20 STEPS] 78.022141 sec\n",
      "[TRAIN] loss : 1.259105, accuracy : 0.310000\n",
      "[TEST loss : 1.046394, accuracy : 0.340000\n",
      "[30 STEPS] 96.033645 sec\n",
      "[TRAIN] loss : 0.953918, accuracy : 0.460000\n",
      "[TEST loss : 0.989929, accuracy : 0.420000\n",
      "[40 STEPS] 111.849215 sec\n",
      "[TRAIN] loss : 0.777493, accuracy : 0.540000\n",
      "[TEST loss : 0.820861, accuracy : 0.500000\n",
      "[50 STEPS] 144.220599 sec\n",
      "[TRAIN] loss : 0.729913, accuracy : 0.450000\n",
      "[TEST loss : 0.700034, accuracy : 0.515000\n",
      "[60 STEPS] 159.387459 sec\n",
      "[TRAIN] loss : 0.662319, accuracy : 0.520000\n",
      "[TEST loss : 0.648080, accuracy : 0.585000\n",
      "[70 STEPS] 175.139361 sec\n",
      "[TRAIN] loss : 0.648043, accuracy : 0.640000\n",
      "[TEST loss : 0.676387, accuracy : 0.615000\n",
      "[80 STEPS] 200.643608 sec\n",
      "[TRAIN] loss : 0.622345, accuracy : 0.640000\n",
      "[TEST loss : 0.656695, accuracy : 0.625000\n",
      "[90 STEPS] 217.951945 sec\n",
      "[TRAIN] loss : 0.730251, accuracy : 0.550000\n",
      "[TEST loss : 0.750167, accuracy : 0.515000\n",
      "[100 STEPS] 239.309410 sec\n",
      "[TRAIN] loss : 0.667929, accuracy : 0.640000\n",
      "[TEST loss : 0.718559, accuracy : 0.580000\n",
      "[110 STEPS] 262.496446 sec\n",
      "[TRAIN] loss : 0.637386, accuracy : 0.640000\n",
      "[TEST loss : 0.730260, accuracy : 0.540000\n",
      "[120 STEPS] 280.880861 sec\n",
      "[TRAIN] loss : 0.746624, accuracy : 0.550000\n",
      "[TEST loss : 0.776588, accuracy : 0.515000\n",
      "[130 STEPS] 298.574561 sec\n",
      "[TRAIN] loss : 0.633142, accuracy : 0.620000\n",
      "[TEST loss : 0.648478, accuracy : 0.610000\n",
      "[140 STEPS] 313.432420 sec\n",
      "[TRAIN] loss : 0.608987, accuracy : 0.640000\n",
      "[TEST loss : 0.650917, accuracy : 0.605000\n",
      "[150 STEPS] 332.312247 sec\n",
      "[TRAIN] loss : 0.684050, accuracy : 0.520000\n",
      "[TEST loss : 0.702897, accuracy : 0.515000\n",
      "[160 STEPS] 347.418565 sec\n",
      "[TRAIN] loss : 0.558632, accuracy : 0.710000\n",
      "[TEST loss : 0.583484, accuracy : 0.685000\n",
      "[170 STEPS] 363.324921 sec\n",
      "[TRAIN] loss : 0.602656, accuracy : 0.670000\n",
      "[TEST loss : 0.639041, accuracy : 0.645000\n",
      "[180 STEPS] 378.447068 sec\n",
      "[TRAIN] loss : 0.593207, accuracy : 0.550000\n",
      "[TEST loss : 0.625293, accuracy : 0.515000\n",
      "[190 STEPS] 393.372215 sec\n",
      "[TRAIN] loss : 0.459008, accuracy : 0.750000\n",
      "[TEST loss : 0.529385, accuracy : 0.735000\n",
      "[200 STEPS] 406.960911 sec\n",
      "[TRAIN] loss : 0.548451, accuracy : 0.700000\n",
      "[TEST loss : 0.718678, accuracy : 0.670000\n",
      "[210 STEPS] 421.892185 sec\n",
      "[TRAIN] loss : 0.505435, accuracy : 0.830000\n",
      "[TEST loss : 0.506161, accuracy : 0.840000\n",
      "[220 STEPS] 436.603774 sec\n",
      "[TRAIN] loss : 0.536651, accuracy : 0.630000\n",
      "[TEST loss : 0.541374, accuracy : 0.675000\n",
      "[230 STEPS] 452.136239 sec\n",
      "[TRAIN] loss : 0.402827, accuracy : 0.840000\n",
      "[TEST loss : 0.492272, accuracy : 0.790000\n",
      "[240 STEPS] 469.754971 sec\n",
      "[TRAIN] loss : 0.409951, accuracy : 0.810000\n",
      "[TEST loss : 0.501029, accuracy : 0.750000\n",
      "[250 STEPS] 486.068098 sec\n",
      "[TRAIN] loss : 0.428213, accuracy : 0.890000\n",
      "[TEST loss : 0.505300, accuracy : 0.835000\n",
      "[260 STEPS] 501.053849 sec\n",
      "[TRAIN] loss : 0.521742, accuracy : 0.790000\n",
      "[TEST loss : 0.479548, accuracy : 0.790000\n",
      "[270 STEPS] 515.675910 sec\n",
      "[TRAIN] loss : 0.446370, accuracy : 0.800000\n",
      "[TEST loss : 0.483605, accuracy : 0.790000\n",
      "[280 STEPS] 534.716150 sec\n",
      "[TRAIN] loss : 0.353590, accuracy : 0.830000\n",
      "[TEST loss : 0.486079, accuracy : 0.775000\n",
      "[290 STEPS] 554.548482 sec\n",
      "[TRAIN] loss : 0.431511, accuracy : 0.810000\n",
      "[TEST loss : 0.560855, accuracy : 0.755000\n",
      "[300 STEPS] 570.161276 sec\n",
      "[TRAIN] loss : 0.467981, accuracy : 0.840000\n",
      "[TEST loss : 0.469371, accuracy : 0.805000\n",
      "[310 STEPS] 584.884351 sec\n",
      "[TRAIN] loss : 0.459153, accuracy : 0.850000\n",
      "[TEST loss : 0.482482, accuracy : 0.850000\n",
      "[320 STEPS] 600.482046 sec\n",
      "[TRAIN] loss : 0.344575, accuracy : 0.870000\n",
      "[TEST loss : 0.473988, accuracy : 0.790000\n",
      "[330 STEPS] 615.107000 sec\n",
      "[TRAIN] loss : 0.392785, accuracy : 0.810000\n",
      "[TEST loss : 0.482088, accuracy : 0.795000\n",
      "[340 STEPS] 629.989209 sec\n",
      "[TRAIN] loss : 0.339531, accuracy : 0.880000\n",
      "[TEST loss : 0.463040, accuracy : 0.835000\n",
      "[350 STEPS] 644.738407 sec\n",
      "[TRAIN] loss : 0.519915, accuracy : 0.840000\n",
      "[TEST loss : 0.475348, accuracy : 0.840000\n",
      "[360 STEPS] 660.340757 sec\n",
      "[TRAIN] loss : 0.441315, accuracy : 0.840000\n",
      "[TEST loss : 0.469751, accuracy : 0.810000\n",
      "[370 STEPS] 678.442522 sec\n",
      "[TRAIN] loss : 0.337314, accuracy : 0.860000\n",
      "[TEST loss : 0.479017, accuracy : 0.785000\n",
      "[380 STEPS] 694.039164 sec\n",
      "[TRAIN] loss : 0.436761, accuracy : 0.820000\n",
      "[TEST loss : 0.547196, accuracy : 0.780000\n",
      "[390 STEPS] 709.214113 sec\n",
      "[TRAIN] loss : 0.458802, accuracy : 0.830000\n",
      "[TEST loss : 0.455650, accuracy : 0.825000\n",
      "[400 STEPS] 725.001572 sec\n",
      "[TRAIN] loss : 0.474675, accuracy : 0.840000\n",
      "[TEST loss : 0.480737, accuracy : 0.845000\n",
      "[410 STEPS] 739.975201 sec\n",
      "[TRAIN] loss : 0.327469, accuracy : 0.870000\n",
      "[TEST loss : 0.457533, accuracy : 0.815000\n",
      "[420 STEPS] 754.673769 sec\n",
      "[TRAIN] loss : 0.378771, accuracy : 0.820000\n",
      "[TEST loss : 0.471149, accuracy : 0.800000\n",
      "[430 STEPS] 769.453966 sec\n",
      "[TRAIN] loss : 0.318770, accuracy : 0.880000\n",
      "[TEST loss : 0.451505, accuracy : 0.815000\n",
      "[440 STEPS] 783.985045 sec\n",
      "[TRAIN] loss : 0.491654, accuracy : 0.810000\n",
      "[TEST loss : 0.460837, accuracy : 0.835000\n",
      "[450 STEPS] 799.587609 sec\n",
      "[TRAIN] loss : 0.423557, accuracy : 0.840000\n",
      "[TEST loss : 0.463536, accuracy : 0.820000\n",
      "[460 STEPS] 815.085906 sec\n",
      "[TRAIN] loss : 0.324589, accuracy : 0.870000\n",
      "[TEST loss : 0.459516, accuracy : 0.800000\n",
      "[470 STEPS] 835.800714 sec\n",
      "[TRAIN] loss : 0.433396, accuracy : 0.820000\n",
      "[TEST loss : 0.535269, accuracy : 0.790000\n",
      "[480 STEPS] 854.127800 sec\n",
      "[TRAIN] loss : 0.446767, accuracy : 0.800000\n",
      "[TEST loss : 0.442769, accuracy : 0.825000\n",
      "[490 STEPS] 869.194936 sec\n",
      "[TRAIN] loss : 0.489989, accuracy : 0.840000\n",
      "[TEST loss : 0.474581, accuracy : 0.840000\n",
      "[500 STEPS] 883.855471 sec\n",
      "[TRAIN] loss : 0.320169, accuracy : 0.890000\n",
      "[TEST loss : 0.442247, accuracy : 0.815000\n",
      "[510 STEPS] 898.488308 sec\n",
      "[TRAIN] loss : 0.369259, accuracy : 0.820000\n",
      "[TEST loss : 0.461406, accuracy : 0.790000\n",
      "[520 STEPS] 913.083087 sec\n",
      "[TRAIN] loss : 0.305468, accuracy : 0.900000\n",
      "[TEST loss : 0.442960, accuracy : 0.815000\n",
      "[530 STEPS] 927.507995 sec\n",
      "[TRAIN] loss : 0.466176, accuracy : 0.810000\n",
      "[TEST loss : 0.450914, accuracy : 0.835000\n",
      "[540 STEPS] 941.534590 sec\n",
      "[TRAIN] loss : 0.411523, accuracy : 0.820000\n",
      "[TEST loss : 0.468855, accuracy : 0.815000\n",
      "[550 STEPS] 955.996848 sec\n",
      "[TRAIN] loss : 0.313914, accuracy : 0.870000\n",
      "[TEST loss : 0.444299, accuracy : 0.805000\n",
      "[560 STEPS] 970.714322 sec\n",
      "[TRAIN] loss : 0.430184, accuracy : 0.830000\n",
      "[TEST loss : 0.526857, accuracy : 0.785000\n",
      "[570 STEPS] 985.418524 sec\n",
      "[TRAIN] loss : 0.450390, accuracy : 0.810000\n",
      "[TEST loss : 0.442544, accuracy : 0.815000\n",
      "[580 STEPS] 1000.149396 sec\n",
      "[TRAIN] loss : 0.515237, accuracy : 0.820000\n",
      "[TEST loss : 0.483160, accuracy : 0.835000\n",
      "[590 STEPS] 1014.887151 sec\n",
      "[TRAIN] loss : 0.317329, accuracy : 0.890000\n",
      "[TEST loss : 0.437860, accuracy : 0.815000\n",
      "[600 STEPS] 1029.489139 sec\n",
      "[TRAIN] loss : 0.367611, accuracy : 0.830000\n",
      "[TEST loss : 0.454564, accuracy : 0.795000\n",
      "[610 STEPS] 1044.106886 sec\n",
      "[TRAIN] loss : 0.305536, accuracy : 0.930000\n",
      "[TEST loss : 0.443800, accuracy : 0.825000\n",
      "[620 STEPS] 1058.800535 sec\n",
      "[TRAIN] loss : 0.466798, accuracy : 0.800000\n",
      "[TEST loss : 0.464450, accuracy : 0.810000\n",
      "[630 STEPS] 1073.513329 sec\n",
      "[TRAIN] loss : 0.407082, accuracy : 0.840000\n",
      "[TEST loss : 0.483448, accuracy : 0.800000\n",
      "[640 STEPS] 1088.465908 sec\n",
      "[TRAIN] loss : 0.315867, accuracy : 0.870000\n",
      "[TEST loss : 0.443683, accuracy : 0.805000\n",
      "[650 STEPS] 1103.063257 sec\n",
      "[TRAIN] loss : 0.437934, accuracy : 0.820000\n",
      "[TEST loss : 0.540231, accuracy : 0.790000\n",
      "[660 STEPS] 1117.705023 sec\n",
      "[TRAIN] loss : 0.453261, accuracy : 0.810000\n",
      "[TEST loss : 0.444282, accuracy : 0.820000\n",
      "[670 STEPS] 1136.621433 sec\n",
      "[TRAIN] loss : 0.531180, accuracy : 0.810000\n",
      "[TEST loss : 0.490847, accuracy : 0.830000\n",
      "[680 STEPS] 1155.954389 sec\n",
      "[TRAIN] loss : 0.311374, accuracy : 0.860000\n",
      "[TEST loss : 0.428799, accuracy : 0.835000\n",
      "[690 STEPS] 1171.749996 sec\n",
      "[TRAIN] loss : 0.353595, accuracy : 0.820000\n",
      "[TEST loss : 0.455788, accuracy : 0.790000\n",
      "[700 STEPS] 1185.975792 sec\n",
      "[TRAIN] loss : 0.290981, accuracy : 0.880000\n",
      "[TEST loss : 0.429164, accuracy : 0.820000\n",
      "[710 STEPS] 1200.768226 sec\n",
      "[TRAIN] loss : 0.438656, accuracy : 0.800000\n",
      "[TEST loss : 0.429715, accuracy : 0.845000\n",
      "[720 STEPS] 1216.252672 sec\n",
      "[TRAIN] loss : 0.385505, accuracy : 0.840000\n",
      "[TEST loss : 0.461754, accuracy : 0.815000\n",
      "[730 STEPS] 1231.045151 sec\n",
      "[TRAIN] loss : 0.302516, accuracy : 0.870000\n",
      "[TEST loss : 0.432722, accuracy : 0.815000\n",
      "[740 STEPS] 1245.595893 sec\n",
      "[TRAIN] loss : 0.424997, accuracy : 0.820000\n",
      "[TEST loss : 0.501762, accuracy : 0.785000\n",
      "[750 STEPS] 1260.725008 sec\n",
      "[TRAIN] loss : 0.443908, accuracy : 0.800000\n",
      "[TEST loss : 0.439426, accuracy : 0.805000\n",
      "[760 STEPS] 1275.610944 sec\n",
      "[TRAIN] loss : 0.490560, accuracy : 0.820000\n",
      "[TEST loss : 0.459122, accuracy : 0.845000\n",
      "[770 STEPS] 1290.251861 sec\n",
      "[TRAIN] loss : 0.308971, accuracy : 0.880000\n",
      "[TEST loss : 0.424177, accuracy : 0.825000\n",
      "[780 STEPS] 1305.270450 sec\n",
      "[TRAIN] loss : 0.352242, accuracy : 0.820000\n",
      "[TEST loss : 0.447810, accuracy : 0.790000\n",
      "[790 STEPS] 1319.891878 sec\n",
      "[TRAIN] loss : 0.284982, accuracy : 0.920000\n",
      "[TEST loss : 0.430430, accuracy : 0.820000\n",
      "[800 STEPS] 1334.466257 sec\n",
      "[TRAIN] loss : 0.438957, accuracy : 0.800000\n",
      "[TEST loss : 0.434726, accuracy : 0.815000\n",
      "[810 STEPS] 1349.357974 sec\n",
      "[TRAIN] loss : 0.395810, accuracy : 0.810000\n",
      "[TEST loss : 0.483835, accuracy : 0.810000\n",
      "[820 STEPS] 1364.185612 sec\n",
      "[TRAIN] loss : 0.295664, accuracy : 0.870000\n",
      "[TEST loss : 0.432477, accuracy : 0.815000\n",
      "[830 STEPS] 1378.875067 sec\n",
      "[TRAIN] loss : 0.420621, accuracy : 0.840000\n",
      "[TEST loss : 0.500920, accuracy : 0.780000\n",
      "[840 STEPS] 1393.507681 sec\n",
      "[TRAIN] loss : 0.463114, accuracy : 0.820000\n",
      "[TEST loss : 0.443491, accuracy : 0.835000\n",
      "[850 STEPS] 1408.812422 sec\n",
      "[TRAIN] loss : 0.531162, accuracy : 0.800000\n",
      "[TEST loss : 0.491094, accuracy : 0.840000\n",
      "[860 STEPS] 1423.165555 sec\n",
      "[TRAIN] loss : 0.305028, accuracy : 0.880000\n",
      "[TEST loss : 0.427914, accuracy : 0.835000\n",
      "[870 STEPS] 1443.764628 sec\n",
      "[TRAIN] loss : 0.358787, accuracy : 0.830000\n",
      "[TEST loss : 0.465242, accuracy : 0.800000\n",
      "[880 STEPS] 1461.074180 sec\n",
      "[TRAIN] loss : 0.293758, accuracy : 0.890000\n",
      "[TEST loss : 0.423156, accuracy : 0.830000\n",
      "[890 STEPS] 1477.312073 sec\n",
      "[TRAIN] loss : 0.438994, accuracy : 0.820000\n",
      "[TEST loss : 0.421279, accuracy : 0.840000\n",
      "[900 STEPS] 1492.107307 sec\n",
      "[TRAIN] loss : 0.372087, accuracy : 0.830000\n",
      "[TEST loss : 0.452514, accuracy : 0.810000\n",
      "[910 STEPS] 1506.891133 sec\n",
      "[TRAIN] loss : 0.307566, accuracy : 0.870000\n",
      "[TEST loss : 0.431343, accuracy : 0.815000\n",
      "[920 STEPS] 1521.544378 sec\n",
      "[TRAIN] loss : 0.418085, accuracy : 0.830000\n",
      "[TEST loss : 0.491349, accuracy : 0.790000\n",
      "[930 STEPS] 1536.051617 sec\n",
      "[TRAIN] loss : 0.436223, accuracy : 0.820000\n",
      "[TEST loss : 0.436516, accuracy : 0.815000\n",
      "[940 STEPS] 1550.787787 sec\n",
      "[TRAIN] loss : 0.469272, accuracy : 0.820000\n",
      "[TEST loss : 0.441568, accuracy : 0.850000\n",
      "[950 STEPS] 1565.365118 sec\n",
      "[TRAIN] loss : 0.306240, accuracy : 0.880000\n",
      "[TEST loss : 0.420365, accuracy : 0.840000\n",
      "[960 STEPS] 1580.163956 sec\n",
      "[TRAIN] loss : 0.344975, accuracy : 0.840000\n",
      "[TEST loss : 0.448574, accuracy : 0.800000\n",
      "[970 STEPS] 1595.231743 sec\n",
      "[TRAIN] loss : 0.276787, accuracy : 0.920000\n",
      "[TEST loss : 0.428512, accuracy : 0.815000\n",
      "[980 STEPS] 1609.882206 sec\n",
      "[TRAIN] loss : 0.446153, accuracy : 0.800000\n",
      "[TEST loss : 0.446255, accuracy : 0.810000\n",
      "[990 STEPS] 1624.929119 sec\n",
      "[TRAIN] loss : 0.383958, accuracy : 0.830000\n",
      "[TEST loss : 0.476758, accuracy : 0.805000\n",
      "[1000 STEPS] 1639.979662 sec\n",
      "[TRAIN] loss : 0.308228, accuracy : 0.880000\n",
      "[TEST loss : 0.440634, accuracy : 0.805000\n",
      "[1010 STEPS] 1654.769986 sec\n",
      "[TRAIN] loss : 0.422523, accuracy : 0.830000\n",
      "[TEST loss : 0.509438, accuracy : 0.790000\n",
      "[1020 STEPS] 1668.944436 sec\n",
      "[TRAIN] loss : 0.461022, accuracy : 0.800000\n",
      "[TEST loss : 0.441492, accuracy : 0.820000\n",
      "[1030 STEPS] 1683.857137 sec\n",
      "[TRAIN] loss : 0.520632, accuracy : 0.780000\n",
      "[TEST loss : 0.479345, accuracy : 0.825000\n",
      "[1040 STEPS] 1699.050022 sec\n",
      "[TRAIN] loss : 0.305503, accuracy : 0.880000\n",
      "[TEST loss : 0.418183, accuracy : 0.850000\n",
      "[1050 STEPS] 1713.983402 sec\n",
      "[TRAIN] loss : 0.340945, accuracy : 0.830000\n",
      "[TEST loss : 0.448757, accuracy : 0.805000\n",
      "[1060 STEPS] 1732.738777 sec\n",
      "[TRAIN] loss : 0.283051, accuracy : 0.880000\n",
      "[TEST loss : 0.418062, accuracy : 0.825000\n",
      "[1070 STEPS] 1750.240932 sec\n",
      "[TRAIN] loss : 0.443411, accuracy : 0.780000\n",
      "[TEST loss : 0.422964, accuracy : 0.850000\n",
      "[1080 STEPS] 1765.033792 sec\n",
      "[TRAIN] loss : 0.364467, accuracy : 0.850000\n",
      "[TEST loss : 0.446301, accuracy : 0.815000\n",
      "[1090 STEPS] 1779.761300 sec\n",
      "[TRAIN] loss : 0.300415, accuracy : 0.880000\n",
      "[TEST loss : 0.425180, accuracy : 0.815000\n",
      "[1100 STEPS] 1794.451466 sec\n",
      "[TRAIN] loss : 0.409454, accuracy : 0.850000\n",
      "[TEST loss : 0.474321, accuracy : 0.800000\n",
      "[1110 STEPS] 1809.292739 sec\n",
      "[TRAIN] loss : 0.427479, accuracy : 0.810000\n",
      "[TEST loss : 0.427456, accuracy : 0.815000\n",
      "[1120 STEPS] 1824.023715 sec\n",
      "[TRAIN] loss : 0.467592, accuracy : 0.810000\n",
      "[TEST loss : 0.440113, accuracy : 0.825000\n",
      "[1130 STEPS] 1838.959270 sec\n",
      "[TRAIN] loss : 0.303565, accuracy : 0.870000\n",
      "[TEST loss : 0.417610, accuracy : 0.830000\n",
      "[1140 STEPS] 1853.856024 sec\n",
      "[TRAIN] loss : 0.340901, accuracy : 0.840000\n",
      "[TEST loss : 0.445660, accuracy : 0.815000\n",
      "[1150 STEPS] 1869.019831 sec\n",
      "[TRAIN] loss : 0.271668, accuracy : 0.910000\n",
      "[TEST loss : 0.424753, accuracy : 0.815000\n",
      "[1160 STEPS] 1883.657310 sec\n",
      "[TRAIN] loss : 0.444901, accuracy : 0.800000\n",
      "[TEST loss : 0.446752, accuracy : 0.815000\n",
      "[1170 STEPS] 1898.093585 sec\n",
      "[TRAIN] loss : 0.367938, accuracy : 0.840000\n",
      "[TEST loss : 0.461054, accuracy : 0.810000\n",
      "[1180 STEPS] 1912.227337 sec\n",
      "[TRAIN] loss : 0.318537, accuracy : 0.880000\n",
      "[TEST loss : 0.455059, accuracy : 0.795000\n",
      "[1190 STEPS] 1926.892061 sec\n",
      "[TRAIN] loss : 0.420844, accuracy : 0.850000\n",
      "[TEST loss : 0.518535, accuracy : 0.790000\n",
      "[1200 STEPS] 1941.551293 sec\n",
      "[TRAIN] loss : 0.481793, accuracy : 0.800000\n",
      "[TEST loss : 0.445087, accuracy : 0.835000\n",
      "[1210 STEPS] 1956.198216 sec\n",
      "[TRAIN] loss : 0.548694, accuracy : 0.770000\n",
      "[TEST loss : 0.502266, accuracy : 0.815000\n",
      "[1220 STEPS] 1970.948231 sec\n",
      "[TRAIN] loss : 0.301479, accuracy : 0.870000\n",
      "[TEST loss : 0.427905, accuracy : 0.840000\n",
      "[1230 STEPS] 1986.329329 sec\n",
      "[TRAIN] loss : 0.352100, accuracy : 0.840000\n",
      "[TEST loss : 0.468003, accuracy : 0.800000\n",
      "[1240 STEPS] 2002.043372 sec\n",
      "[TRAIN] loss : 0.280772, accuracy : 0.890000\n",
      "[TEST loss : 0.417979, accuracy : 0.835000\n",
      "[1250 STEPS] 2017.173290 sec\n",
      "[TRAIN] loss : 0.440916, accuracy : 0.780000\n",
      "[TEST loss : 0.418192, accuracy : 0.850000\n",
      "[1260 STEPS] 2035.271878 sec\n",
      "[TRAIN] loss : 0.359629, accuracy : 0.850000\n",
      "[TEST loss : 0.435054, accuracy : 0.815000\n",
      "[1270 STEPS] 2052.428879 sec\n",
      "[TRAIN] loss : 0.291145, accuracy : 0.890000\n",
      "[TEST loss : 0.416777, accuracy : 0.840000\n",
      "[1280 STEPS] 2067.255749 sec\n",
      "[TRAIN] loss : 0.396652, accuracy : 0.860000\n",
      "[TEST loss : 0.448674, accuracy : 0.810000\n",
      "[1290 STEPS] 2083.281671 sec\n",
      "[TRAIN] loss : 0.416734, accuracy : 0.810000\n",
      "[TEST loss : 0.419162, accuracy : 0.825000\n",
      "[1300 STEPS] 2096.287150 sec\n",
      "[TRAIN] loss : 0.476881, accuracy : 0.830000\n",
      "[TEST loss : 0.446950, accuracy : 0.815000\n",
      "[1310 STEPS] 2108.779434 sec\n",
      "[TRAIN] loss : 0.308810, accuracy : 0.850000\n",
      "[TEST loss : 0.420861, accuracy : 0.825000\n",
      "[1320 STEPS] 2121.261010 sec\n",
      "[TRAIN] loss : 0.336997, accuracy : 0.840000\n",
      "[TEST loss : 0.444509, accuracy : 0.820000\n",
      "[1330 STEPS] 2133.668263 sec\n",
      "[TRAIN] loss : 0.271058, accuracy : 0.920000\n",
      "[TEST loss : 0.424752, accuracy : 0.815000\n",
      "[1340 STEPS] 2146.123904 sec\n",
      "[TRAIN] loss : 0.451067, accuracy : 0.810000\n",
      "[TEST loss : 0.456670, accuracy : 0.810000\n",
      "[1350 STEPS] 2158.654417 sec\n",
      "[TRAIN] loss : 0.369872, accuracy : 0.830000\n",
      "[TEST loss : 0.461289, accuracy : 0.815000\n",
      "[1360 STEPS] 2170.988893 sec\n",
      "[TRAIN] loss : 0.303112, accuracy : 0.870000\n",
      "[TEST loss : 0.454887, accuracy : 0.825000\n",
      "[1370 STEPS] 2183.311847 sec\n",
      "[TRAIN] loss : 0.433130, accuracy : 0.820000\n",
      "[TEST loss : 0.544874, accuracy : 0.795000\n",
      "[1380 STEPS] 2197.616650 sec\n",
      "[TRAIN] loss : 0.447970, accuracy : 0.810000\n",
      "[TEST loss : 0.437622, accuracy : 0.820000\n",
      "[1390 STEPS] 2210.192068 sec\n",
      "[TRAIN] loss : 0.482745, accuracy : 0.820000\n",
      "[TEST loss : 0.449271, accuracy : 0.815000\n",
      "[1400 STEPS] 2222.617736 sec\n",
      "[TRAIN] loss : 0.309331, accuracy : 0.880000\n",
      "[TEST loss : 0.414177, accuracy : 0.835000\n",
      "[1410 STEPS] 2235.431122 sec\n",
      "[TRAIN] loss : 0.325398, accuracy : 0.840000\n",
      "[TEST loss : 0.430475, accuracy : 0.835000\n",
      "[1420 STEPS] 2247.927936 sec\n",
      "[TRAIN] loss : 0.286651, accuracy : 0.890000\n",
      "[TEST loss : 0.408839, accuracy : 0.835000\n",
      "[1430 STEPS] 2261.541719 sec\n",
      "[TRAIN] loss : 0.462155, accuracy : 0.790000\n",
      "[TEST loss : 0.431009, accuracy : 0.840000\n",
      "[1440 STEPS] 2274.888668 sec\n",
      "[TRAIN] loss : 0.353620, accuracy : 0.860000\n",
      "[TEST loss : 0.434771, accuracy : 0.815000\n",
      "[1450 STEPS] 2288.218498 sec\n",
      "[TRAIN] loss : 0.291253, accuracy : 0.900000\n",
      "[TEST loss : 0.411472, accuracy : 0.830000\n",
      "[1460 STEPS] 2300.728632 sec\n",
      "[TRAIN] loss : 0.405861, accuracy : 0.840000\n",
      "[TEST loss : 0.473104, accuracy : 0.800000\n",
      "[1470 STEPS] 2313.135009 sec\n",
      "[TRAIN] loss : 0.416476, accuracy : 0.830000\n",
      "[TEST loss : 0.433461, accuracy : 0.815000\n",
      "[1480 STEPS] 2326.906482 sec\n",
      "[TRAIN] loss : 0.460005, accuracy : 0.830000\n",
      "[TEST loss : 0.438195, accuracy : 0.820000\n",
      "[1490 STEPS] 2341.160110 sec\n",
      "[TRAIN] loss : 0.307803, accuracy : 0.880000\n",
      "[TEST loss : 0.414930, accuracy : 0.835000\n",
      "[1500 STEPS] 2356.339076 sec\n",
      "[TRAIN] loss : 0.334190, accuracy : 0.840000\n",
      "[TEST loss : 0.452746, accuracy : 0.825000\n",
      "[1510 STEPS] 2368.920300 sec\n",
      "[TRAIN] loss : 0.290207, accuracy : 0.880000\n",
      "[TEST loss : 0.406744, accuracy : 0.835000\n",
      "[1520 STEPS] 2381.388941 sec\n",
      "[TRAIN] loss : 0.488131, accuracy : 0.780000\n",
      "[TEST loss : 0.452324, accuracy : 0.835000\n",
      "[1530 STEPS] 2393.763083 sec\n",
      "[TRAIN] loss : 0.347840, accuracy : 0.860000\n",
      "[TEST loss : 0.426147, accuracy : 0.830000\n",
      "[1540 STEPS] 2406.204964 sec\n",
      "[TRAIN] loss : 0.288779, accuracy : 0.900000\n",
      "[TEST loss : 0.416033, accuracy : 0.830000\n",
      "[1550 STEPS] 2418.602492 sec\n",
      "[TRAIN] loss : 0.401263, accuracy : 0.830000\n",
      "[TEST loss : 0.482177, accuracy : 0.800000\n",
      "[1560 STEPS] 2431.017015 sec\n",
      "[TRAIN] loss : 0.411683, accuracy : 0.830000\n",
      "[TEST loss : 0.427667, accuracy : 0.830000\n",
      "[1570 STEPS] 2443.499770 sec\n",
      "[TRAIN] loss : 0.459170, accuracy : 0.830000\n",
      "[TEST loss : 0.434325, accuracy : 0.815000\n",
      "[1580 STEPS] 2455.941339 sec\n",
      "[TRAIN] loss : 0.302929, accuracy : 0.880000\n",
      "[TEST loss : 0.410165, accuracy : 0.835000\n",
      "[1590 STEPS] 2468.415375 sec\n",
      "[TRAIN] loss : 0.339343, accuracy : 0.840000\n",
      "[TEST loss : 0.464025, accuracy : 0.830000\n",
      "[1600 STEPS] 2480.784386 sec\n",
      "[TRAIN] loss : 0.291196, accuracy : 0.890000\n",
      "[TEST loss : 0.404137, accuracy : 0.835000\n",
      "[1610 STEPS] 2493.173649 sec\n",
      "[TRAIN] loss : 0.484698, accuracy : 0.780000\n",
      "[TEST loss : 0.451770, accuracy : 0.840000\n",
      "[1620 STEPS] 2505.565718 sec\n",
      "[TRAIN] loss : 0.342657, accuracy : 0.860000\n",
      "[TEST loss : 0.422394, accuracy : 0.830000\n",
      "[1630 STEPS] 2517.896022 sec\n",
      "[TRAIN] loss : 0.291347, accuracy : 0.890000\n",
      "[TEST loss : 0.425932, accuracy : 0.830000\n",
      "[1640 STEPS] 2530.330510 sec\n",
      "[TRAIN] loss : 0.390274, accuracy : 0.850000\n",
      "[TEST loss : 0.480687, accuracy : 0.810000\n",
      "[1650 STEPS] 2542.772890 sec\n",
      "[TRAIN] loss : 0.421469, accuracy : 0.820000\n",
      "[TEST loss : 0.415117, accuracy : 0.840000\n",
      "[1660 STEPS] 2555.130098 sec\n",
      "[TRAIN] loss : 0.481238, accuracy : 0.820000\n",
      "[TEST loss : 0.447450, accuracy : 0.830000\n",
      "[1670 STEPS] 2567.542007 sec\n",
      "[TRAIN] loss : 0.301280, accuracy : 0.860000\n",
      "[TEST loss : 0.411041, accuracy : 0.840000\n",
      "[1680 STEPS] 2579.980376 sec\n",
      "[TRAIN] loss : 0.331168, accuracy : 0.850000\n",
      "[TEST loss : 0.438346, accuracy : 0.840000\n",
      "[1690 STEPS] 2592.400288 sec\n",
      "[TRAIN] loss : 0.265208, accuracy : 0.900000\n",
      "[TEST loss : 0.407407, accuracy : 0.835000\n",
      "[1700 STEPS] 2604.791745 sec\n",
      "[TRAIN] loss : 0.473069, accuracy : 0.790000\n",
      "[TEST loss : 0.463581, accuracy : 0.805000\n",
      "[1710 STEPS] 2617.130266 sec\n",
      "[TRAIN] loss : 0.345428, accuracy : 0.870000\n",
      "[TEST loss : 0.412882, accuracy : 0.830000\n",
      "[1720 STEPS] 2630.973964 sec\n",
      "[TRAIN] loss : 0.272839, accuracy : 0.910000\n",
      "[TEST loss : 0.416097, accuracy : 0.830000\n",
      "[1730 STEPS] 2645.832710 sec\n",
      "[TRAIN] loss : 0.377802, accuracy : 0.860000\n",
      "[TEST loss : 0.461287, accuracy : 0.815000\n",
      "[1740 STEPS] 2660.243360 sec\n",
      "[TRAIN] loss : 0.400959, accuracy : 0.830000\n",
      "[TEST loss : 0.401214, accuracy : 0.855000\n",
      "[1750 STEPS] 2672.898157 sec\n",
      "[TRAIN] loss : 0.503927, accuracy : 0.810000\n",
      "[TEST loss : 0.464215, accuracy : 0.810000\n",
      "[1760 STEPS] 2685.496842 sec\n",
      "[TRAIN] loss : 0.300618, accuracy : 0.890000\n",
      "[TEST loss : 0.409146, accuracy : 0.855000\n",
      "[1770 STEPS] 2698.021174 sec\n",
      "[TRAIN] loss : 0.324273, accuracy : 0.850000\n",
      "[TEST loss : 0.436232, accuracy : 0.825000\n",
      "[1780 STEPS] 2710.582856 sec\n",
      "[TRAIN] loss : 0.270961, accuracy : 0.900000\n",
      "[TEST loss : 0.397332, accuracy : 0.835000\n",
      "[1790 STEPS] 2722.950124 sec\n",
      "[TRAIN] loss : 0.492706, accuracy : 0.750000\n",
      "[TEST loss : 0.458868, accuracy : 0.855000\n",
      "[1800 STEPS] 2735.372911 sec\n",
      "[TRAIN] loss : 0.337087, accuracy : 0.870000\n",
      "[TEST loss : 0.411476, accuracy : 0.830000\n",
      "[1810 STEPS] 2747.830750 sec\n",
      "[TRAIN] loss : 0.274450, accuracy : 0.890000\n",
      "[TEST loss : 0.410105, accuracy : 0.835000\n",
      "[1820 STEPS] 2760.346664 sec\n",
      "[TRAIN] loss : 0.373012, accuracy : 0.860000\n",
      "[TEST loss : 0.490264, accuracy : 0.810000\n",
      "[1830 STEPS] 2772.856456 sec\n",
      "[TRAIN] loss : 0.399147, accuracy : 0.840000\n",
      "[TEST loss : 0.410563, accuracy : 0.850000\n",
      "[1840 STEPS] 2785.259932 sec\n",
      "[TRAIN] loss : 0.516867, accuracy : 0.810000\n",
      "[TEST loss : 0.481215, accuracy : 0.835000\n",
      "[1850 STEPS] 2797.689158 sec\n",
      "[TRAIN] loss : 0.292754, accuracy : 0.900000\n",
      "[TEST loss : 0.418711, accuracy : 0.845000\n",
      "[1860 STEPS] 2811.355128 sec\n",
      "[TRAIN] loss : 0.358326, accuracy : 0.830000\n",
      "[TEST loss : 0.448689, accuracy : 0.820000\n",
      "[1870 STEPS] 2823.999223 sec\n",
      "[TRAIN] loss : 0.251634, accuracy : 0.900000\n",
      "[TEST loss : 0.395630, accuracy : 0.845000\n",
      "[1880 STEPS] 2836.446577 sec\n",
      "[TRAIN] loss : 0.407678, accuracy : 0.830000\n",
      "[TEST loss : 0.385404, accuracy : 0.845000\n",
      "[1890 STEPS] 2848.969227 sec\n",
      "[TRAIN] loss : 0.355143, accuracy : 0.870000\n",
      "[TEST loss : 0.389154, accuracy : 0.850000\n",
      "[1900 STEPS] 2861.359633 sec\n",
      "[TRAIN] loss : 0.252680, accuracy : 0.930000\n",
      "[TEST loss : 0.386185, accuracy : 0.855000\n",
      "[1910 STEPS] 2873.814341 sec\n",
      "[TRAIN] loss : 1.099654, accuracy : 0.480000\n",
      "[TEST loss : 0.972844, accuracy : 0.515000\n",
      "[1920 STEPS] 2886.230305 sec\n",
      "[TRAIN] loss : 0.498847, accuracy : 0.760000\n",
      "[TEST loss : 0.505790, accuracy : 0.770000\n",
      "[1930 STEPS] 2898.608628 sec\n",
      "[TRAIN] loss : 0.410405, accuracy : 0.830000\n",
      "[TEST loss : 0.425207, accuracy : 0.815000\n",
      "[1940 STEPS] 2911.029060 sec\n",
      "[TRAIN] loss : 0.301172, accuracy : 0.890000\n",
      "[TEST loss : 0.438685, accuracy : 0.810000\n",
      "[1950 STEPS] 2924.391900 sec\n",
      "[TRAIN] loss : 0.363668, accuracy : 0.820000\n",
      "[TEST loss : 0.455289, accuracy : 0.800000\n",
      "[1960 STEPS] 2940.135107 sec\n",
      "[TRAIN] loss : 0.295024, accuracy : 0.890000\n",
      "[TEST loss : 0.426995, accuracy : 0.830000\n",
      "[1970 STEPS] 2955.257427 sec\n",
      "[TRAIN] loss : 0.439263, accuracy : 0.780000\n",
      "[TEST loss : 0.436729, accuracy : 0.850000\n",
      "[1980 STEPS] 2968.175414 sec\n",
      "[TRAIN] loss : 0.371277, accuracy : 0.850000\n",
      "[TEST loss : 0.447915, accuracy : 0.825000\n",
      "[1990 STEPS] 2980.652382 sec\n",
      "[TRAIN] loss : 0.294690, accuracy : 0.890000\n",
      "[TEST loss : 0.425346, accuracy : 0.830000\n",
      "[2000 STEPS] 2993.347624 sec\n",
      "[TRAIN] loss : 0.419171, accuracy : 0.840000\n",
      "[TEST loss : 0.485211, accuracy : 0.795000\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "sess = tf.InteractiveSession()\n",
    "ckpt = tf.train.get_checkpoint_state(CKPTDIR)\n",
    "if ckpt:\n",
    "    # checkpointファイルから最後に保存したモデルへのパスを取得する\n",
    "    last_model = ckpt.model_checkpoint_path\n",
    "    print((\"load {0}\".format(last_model)))\n",
    "    # 学習済みモデルを読み込む\n",
    "    saver.restore(sess, last_model)\n",
    "    LOAD_MODEL = True\n",
    "else:\n",
    "  #チェックポイントを作成する\n",
    "  print(\"initialization\")\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  start = time()\n",
    "  i = 0\n",
    "  for _ in range(NUM_STEPS):\n",
    "      cycle = int((NUM_DATA-NUM_TEST)/SIZE_BATCH)\n",
    "      begin = int(SIZE_BATCH * (i % cycle))\n",
    "      end = int(begin + SIZE_BATCH)\n",
    "      batch_x, batch_t = x_train_data[begin:end], y_train_label[begin:end]\n",
    "      i += 1\n",
    "      sess.run(train_step, feed_dict={x: batch_x, t: batch_t})\n",
    "      if i % 10 == 0:\n",
    "          loss_, acc_ = sess.run([loss, accuracy], feed_dict={x: batch_x, t: batch_t})\n",
    "          loss_train.append(loss_)\n",
    "          acc_train.append(acc_)\n",
    "          loss_test_, acc_test_ = sess.run([loss, accuracy], feed_dict={x: x_test_data, t: y_test_label})\n",
    "          loss_test.append(loss_test_)\n",
    "          acc_test.append(acc_test_)\n",
    "          print(\"[%i STEPS] %f sec\" % (i, (time() - start)))\n",
    "          print(\"[TRAIN] loss : %f, accuracy : %f\" %(loss_, acc_))\n",
    "          print(\"[TEST loss : %f, accuracy : %f\" %(loss_test_, acc_test_))\n",
    "\n",
    "  #チェックポイントを保存する\n",
    "  saver.save(sess, CKPTDIR+\"/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
